---
title: "Predicting NBA shots"
output: html_notebook
---

# Set up
```{r}
# Code which explores the NBA shot log data
# clear workspace
remove(list = ls())
# clear console
cat("\014")

# load packages
library(tidyverse)
library(skimr)
library(ggplot2)
library(caret)
library(tictoc)
library(corrplot)
library(pROC)
library(kernlab)

path_project <- "C:/Users/Mats Ole/Desktop/predicting_nba_shots/"
path_rel_data <- "data_input/"
name_data <- "shot_logs.csv"

df_raw <- read_csv(paste0(path_project, path_rel_data, name_data))

# data cleaning ----------------------------------------------------------------
df_clean <- df_raw %>%
  transmute(game_id = as.factor(GAME_ID),
            matchup = as.factor(MATCHUP),
            home_game = case_when(LOCATION == "H" ~ TRUE,
                                  LOCATION == "A" ~ FALSE),
            win = case_when(W == "W" ~ TRUE,
                           W == "L" ~ FALSE),
            final_margin = abs(FINAL_MARGIN),
            shot_number = SHOT_NUMBER,
            period = PERIOD,
            game_clock = as.numeric(GAME_CLOCK),
            shot_clock = SHOT_CLOCK,
            dribbles = DRIBBLES,
            touch_time = TOUCH_TIME,
            shot_dist = SHOT_DIST,
            pts_type = as.factor(PTS_TYPE),
            shot_result = as.factor(SHOT_RESULT),
            closest_defender = as.factor(CLOSEST_DEFENDER),
            closest_defender_id = CLOSEST_DEFENDER_PLAYER_ID,
            closest_defender_dist = CLOSE_DEF_DIST,
            pts = PTS,
            player_name = as.factor(player_name),
            player_id = player_id) %>%
  drop_na() %>%
  select(shot_result, everything())
```

# Data exploration


```{r, results='asis'}
kable(skim(df_clean))
mean(df_clean$shot_result == "made")
```

```{r}
correlations <- cor(df_clean_2 %>% select(-fgm))
corrplot(correlations, order = "hclust")

ggplot(df_clean_2[1:10000,], aes(x = shot_dist,
                                 y = closest_defender_dist,
                                 color = fgm)) +
  geom_point(alpha = 1/10)
```


```{r}
# pre-process the data ---------------------------------------------------------
set.seed(111)

# create dummy variables and interactions

# stratified random split of the data
df <- df_clean # only look at part of the data for exploratory analysis
in_training <- createDataPartition(y = df$fgm, p = 0.05, list = FALSE)
df_train <- df[in_training, ]
df_test <- df[-in_training,]

# set up
fitted_models <- list()
model_predictions <- list()
fit_control <- trainControl(method = "repeatedcv", number = 10, repeats = 5,
                            classProbs = TRUE,
                            summaryFunction = twoClassSummary)
pre_proc_options <- c("center", "scale")
optimisation_metric <- "ROC"
length_tune_grid <- 10 

grids <- list()
model_specs <- list()

# calibration_plot function
make_calibration_plot <- function(df, fitted_model) {
  df$probs <- predict.train(fitted_model, df, type = "prob")[,1]
  # event is missed shot
  calibration_curve <- calibration(fgm ~ probs, data = df)
  xyplot(calibration_curve, auto.key = list(columns = 2))
}

make_roc_plot <- function(df, fitted_model) {
  df$probs <- predict.train(fitted_model, df, type = "prob")[,2]
  roc_curve <- roc(response = df$fgm, predictor = df$probs)
  print(auc(roc_curve))
  plot(roc_curve, legacy.axes = TRUE)
}
```

# Regression type models
```{r}

model_specs$regression <- fgm ~ shot_dist + I(shot_dist^2) + 
                                closest_defender_dist + 
                                I(closest_defender_dist^2) + 
                                shot_clock +
                                I(final_margin^2) +
                                touch_time +
                                home_game


#grids$ridge <- expand.grid(alpha = 0,lambda = 10^(seq(-9, -2)))
#grids$lasso <- expand.grid(alpha = 1,lambda = 10^(seq(-9, -2)))
grids$ridge <- expand.grid(alpha = 0,lambda = seq(0, 0.02, length = 10))
grids$lasso <- expand.grid(alpha = 1,lambda = seq(0, 0.003, length = 10))
```


## ridge
```{r}
tic()
fitted_models[["ridge"]] <- train(model_specs$regression, data = df_train,
                                  method = "glmnet",
                                  metric = optimisation_metric,
                                  preProc = pre_proc_options,
                                  trControl = fit_control,
                                  tuneGrid = grids[["ridge"]])
                                  #tuneLength = length_tune_grid)
model_predictions[["ridge"]] <- predict.train(fitted_models[["ridge"]], df_test)
model_predictions[["ridge_probs"]] <- predict.train(fitted_models[["ridge"]], df_test, type = "prob")
toc()
```

```{r}
confusionMatrix(model_predictions$ridge,df_test$fgm, positive = "hit")
varImp(fitted_models$ridge)
plot(fitted_models$ridge)
fitted_models$ridge
predictors(fitted_models$ridge)
coef(fitted_models$ridge$finalModel, fitted_models$ridge$bestTune$lambda)
make_calibration_plot(df_train, fitted_models$ridge)
make_calibration_plot(df_test, fitted_models$ridge)

make_roc_plot(df_train, fitted_models$ridge)
make_roc_plot(df_test, fitted_models$ridge)

# df_train$probs <- predict.train(fitted_models$ridge, df_train, type = "prob")[,2]
# roc_curve <- roc(response = df_train$fgm, predictor = df_train$probs)
# auc(roc_curve)
# plot(roc_curve, legacy.axes = TRUE)
```


## lasso
```{r}
tic()
fitted_models[["lasso"]] <- train(model_specs$regression, data = df_train,
                                  method = "glmnet",
                                  metric = optimisation_metric,
                                  preProc = pre_proc_options,
                                  trControl = fit_control,
                                  tuneGrid = grids[["lasso"]])
                                  #tuneLength = length_tune_grid)
model_predictions[["lasso"]] <- predict.train(fitted_models[["lasso"]], df_test)
toc()
```

```{r}
confusionMatrix(model_predictions$lasso,df_test$fgm, positive = "hit")
varImp(fitted_models$lasso)
plot(fitted_models$lasso)
fitted_models$lasso
predictors(fitted_models$lasso)
coef(fitted_models$lasso$finalModel, fitted_models$lasso$bestTune$lambda)
make_calibration_plot(df_train, fitted_models$lasso)
make_calibration_plot(df_test, fitted_models$lasso)

make_roc_plot(df_train, fitted_models$lasso)
make_roc_plot(df_test, fitted_models$lasso)

```


# Non-parametric models
## knn
```{r}
model_specs$knn = fgm ~ shot_dist + closest_defender_dist + touch_time + shot_clock
grids$knn <- expand.grid(k = seq(1, 200, length = 10))

# knn
tic()
fitted_models[["knn"]] <- train(model_specs$knn,
                                data = df_train,
                                method = "knn",
                                metric = optimisation_metric,
                                preProc = pre_proc_options,
                                trControl = fit_control,
                                tuneGrid = grids[["knn"]])
                                #tuneLength = length_tune_grid)
model_predictions[["knn"]] <- predict.train(fitted_models[["knn"]], df_test)
toc()
```

```{r}
confusionMatrix(model_predictions[["knn"]],df_test$fgm, positive = "hit")
#varImp(fitted_models$knn) not implicable to knn
plot(fitted_models[["knn"]])
fitted_models[["knn"]]
predictors(fitted_models[["knn"]])
# problem seems to be some shots that are predicted to surely miss but score instead
make_calibration_plot(df_train, fitted_models$knn)
make_calibration_plot(df_test, fitted_models$knn)

make_roc_plot(df_train, fitted_models$knn)
make_roc_plot(df_test, fitted_models$knn)

```


## SVM

### Linear

```{r}
model_specs$svm = fgm ~ shot_dist + closest_defender_dist + touch_time + shot_clock
```
```{r}

# knn
tic()
fitted_models[["svm"]] <- train(model_specs$svm,
                                data = df_train,
                                method = "svmLinear",
                                metric = optimisation_metric,
                                preProc = pre_proc_options,
                                trControl = fit_control)
                                #tuneLength = length_tune_grid)
toc()
tic()
model_predictions[["svm"]] <- predict.train(fitted_models[["svm"]], df_test)
toc()
```
```{r}
confusionMatrix(model_predictions[["svm"]],df_test$fgm, positive = "hit")
#varImp(fitted_models$svm) not implicable to svm
#plot(fitted_models[["svm"]])
fitted_models[["svm"]]
predictors(fitted_models[["svm"]])
# problem seems to be some shots that are predicted to surely miss but score instead
make_calibration_plot(df_train, fitted_models$svm)
make_calibration_plot(df_test, fitted_models$svm)

make_roc_plot(df_train, fitted_models$svm)
make_roc_plot(df_test, fitted_models$svm)
```

### Radial

```{r}
model_specs$svm = fgm ~ shot_dist + closest_defender_dist + touch_time + shot_clock
# create reduced df to analytically estimate sigma
reduced_set <- c("shot_dist", "closest_defender_dist", "touch_time", "shot_clock")
sigmaRangeReduced <- sigest(as.matrix(df_train[,reduced_set]))
grids$svm <- expand.grid(.sigma = sigmaRangeReduced[1], .C = 2^(seq(-1, 1)))
```
```{r}
fit_control_svm <- trainControl(method = "repeatedcv", number = 5, repeats = 1,
                            classProbs = TRUE,
                            summaryFunction = twoClassSummary)

# knn
tic()
fitted_models[["svm_r"]] <- train(model_specs$svm,
                                data = df_train,
                                method = "svmRadial",
                                metric = optimisation_metric,
                                preProc = pre_proc_options,
                                trControl = fit_control,
                                tuneGrid = grids[["svm"]])
toc()
tic()
model_predictions[["svm_r"]] <- predict.train(fitted_models[["svm_r"]], df_test)
toc()
```

```{r}
confusionMatrix(model_predictions[["svm_r"]],df_test$fgm, positive = "hit")
#varImp(fitted_models$svm) not implicable to svm
plot(fitted_models[["svm_r"]])
fitted_models[["svm_r"]]
predictors(fitted_models[["svm_r"]])
# problem seems to be some shots that are predicted to surely miss but score instead
make_calibration_plot(df_train, fitted_models$svm)
make_calibration_plot(df_test, fitted_models$svm)

make_roc_plot(df_train, fitted_models$svm)
make_roc_plot(df_test, fitted_models$svm)

```


Next steps

0. SVM
1. Random forrests
2. Partial least squares
3. Neural Networks
