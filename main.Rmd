---
title: "Predicting NBA shots"
output: html_notebook
---

# Set up
```{r}
# Code which explores the NBA shot log data
# clear workspace
remove(list = ls())
# clear console
cat("\014")

# load packages
library(tidyverse)
library(skimr)
library(ggplot2)
library(caret)
library(tictoc)
library(corrplot)
library(pROC)
library(kernlab)

path_project <- "C:/Users/Mats Ole/Desktop/predicting_nba_shots/"
path_rel_data <- "data_input/"
name_data <- "shot_logs.csv"

df_raw <- read_csv(paste0(path_project, path_rel_data, name_data))

# data cleaning ----------------------------------------------------------------
df_clean <- df_raw %>%
  transmute(game_id = GAME_ID,
            matchup = as.factor(MATCHUP),
            home_game = case_when(LOCATION == "H" ~ TRUE,
                                  LOCATION == "A" ~ FALSE),
            win = case_when(W == "W" ~ TRUE,
                           W == "L" ~ FALSE),
            final_margin = abs(FINAL_MARGIN),
            shot_number = SHOT_NUMBER,
            period = PERIOD,
            game_clock = as.numeric(GAME_CLOCK),
            shot_clock = SHOT_CLOCK,
            dribbles = DRIBBLES,
            touch_time = TOUCH_TIME,
            shot_dist = SHOT_DIST,
            pts_type = as.factor(PTS_TYPE),
            fgm = as.factor(case_when(FGM == 1 ~ "hit",
                                      FGM == 0 ~ "miss")),
            closest_defender = as.factor(CLOSEST_DEFENDER),
            closest_defender_id = CLOSEST_DEFENDER_PLAYER_ID,
            closest_defender_dist = CLOSE_DEF_DIST,
            pts = PTS,
            player_name = as.factor(player_name),
            player_id = player_id) %>%
  drop_na() %>%
  select(fgm, everything())

# Adding square terms, interactions and dummies
df_clean_2 <- cbind(df_clean[,"fgm"], as.data.frame(model.matrix(fgm ~ - 1 +
                                               shot_clock +
                                               poly(shot_dist, degree = 2, raw = TRUE) * pts_type +
                                               closest_defender_dist +
                                               final_margin^2 +
                                               touch_time +
                                               #player_name +
                                                 #closest_defender,
                                                 home_game,
                                             data = df_clean))) %>%
  mutate(fgm = as.factor(fgm)) %>%
  rename(shot_dist = `poly(shot_dist, degree = 2, raw = TRUE)1`,
         shot_dist_2 = `poly(shot_dist, degree = 2, raw = TRUE)2`,
         shot_dist_3pts = `poly(shot_dist, degree = 2, raw = TRUE)1:pts_type3`,
         shot_dist_2_3pts = `poly(shot_dist, degree = 2, raw = TRUE)2:pts_type3`)
```

# Data exploration

```{r}
mean(as.numeric(df_clean_2$fgm) - 1)
head(as.numeric(df_clean_2$fgm) - 1)
head(df_clean_2$fgm)
```

```{r}
correlations <- cor(df_clean_2 %>% select(-fgm))
corrplot(correlations, order = "hclust")

ggplot(df_clean_2[1:10000,], aes(x = shot_dist,
                                 y = closest_defender_dist,
                                 color = fgm)) +
  geom_point(alpha = 1/10)
```


```{r}
# pre-process the data ---------------------------------------------------------
set.seed(111)

# create dummy variables and interactions

# stratified random split of the data
df <- df_clean_2 # only look at part of the data for exploratory analysis
in_training <- createDataPartition(y = df$fgm, p = 0.05, list = FALSE)
df_train <- df[in_training, ]
df_test <- df[-in_training,]

# set up
fitted_models <- list()
model_predictions <- list()
fit_control <- trainControl(method = "repeatedcv", number = 10, repeats = 5,
                            classProbs = TRUE,
                            summaryFunction = twoClassSummary)
pre_proc_options <- c("center", "scale")
optimisation_metric <- "ROC"
length_tune_grid <- 10 

grids <- list()
model_specs <- list()

# calibration_plot function
make_calibration_plot <- function(df, fitted_model) {
  df$probs <- predict.train(fitted_model, df, type = "prob")[,1]
  # event is missed shot
  calibration_curve <- calibration(fgm ~ probs, data = df)
  xyplot(calibration_curve, auto.key = list(columns = 2))
}

make_roc_plot <- function(df, fitted_model) {
  df$probs <- predict.train(fitted_model, df, type = "prob")[,2]
  roc_curve <- roc(response = df$fgm, predictor = df$probs)
  print(auc(roc_curve))
  plot(roc_curve, legacy.axes = TRUE)
}
```

# Regression type models
```{r}

model_specs$regression <- fgm ~ .
grids$ridge <- expand.grid(alpha = 0,lambda = seq(0, 0.1, length = 10))
grids$lasso <- expand.grid(alpha = 1,lambda = seq(0, 0.1, length = 10))
```


## ridge
```{r}
tic()
fitted_models[["ridge"]] <- train(model_specs$regression, data = df_train,
                                  method = "glmnet",
                                  metric = optimisation_metric,
                                  preProc = pre_proc_options,
                                  trControl = fit_control,
                                  tuneGrid = grids[["ridge"]])
                                  #tuneLength = length_tune_grid)
model_predictions[["ridge"]] <- predict.train(fitted_models[["ridge"]], df_test)
model_predictions[["ridge_probs"]] <- predict.train(fitted_models[["ridge"]], df_test, type = "prob")
toc()
```

```{r}
confusionMatrix(model_predictions$ridge,df_test$fgm, positive = "hit")
varImp(fitted_models$ridge)
plot(fitted_models$ridge)
fitted_models$ridge
predictors(fitted_models$ridge)
coef(fitted_models$ridge$finalModel, fitted_models$ridge$bestTune$lambda)
make_calibration_plot(df_train, fitted_models$ridge)
make_calibration_plot(df_test, fitted_models$ridge)

make_roc_plot(df_train, fitted_models$ridge)
make_roc_plot(df_test, fitted_models$ridge)

# df_train$probs <- predict.train(fitted_models$ridge, df_train, type = "prob")[,2]
# roc_curve <- roc(response = df_train$fgm, predictor = df_train$probs)
# auc(roc_curve)
# plot(roc_curve, legacy.axes = TRUE)
```


## lasso
```{r}
tic()
fitted_models[["lasso"]] <- train(model_specs$regression, data = df_train,
                                  method = "glmnet",
                                  metric = optimisation_metric,
                                  preProc = pre_proc_options,
                                  trControl = fit_control,
                                  tuneGrid = grids[["lasso"]])
                                  #tuneLength = length_tune_grid)
model_predictions[["lasso"]] <- predict.train(fitted_models[["lasso"]], df_test)
toc()
```

```{r}
confusionMatrix(model_predictions$lasso,df_test$fgm, positive = "hit")
varImp(fitted_models$lasso)
plot(fitted_models$lasso)
fitted_models$lasso
predictors(fitted_models$lasso)
coef(fitted_models$lasso$finalModel, fitted_models$lasso$bestTune$lambda)
make_calibration_plot(df_train, fitted_models$lasso)
make_calibration_plot(df_test, fitted_models$lasso)

make_roc_plot(df_train, fitted_models$lasso)
make_roc_plot(df_test, fitted_models$lasso)

```


# Non-parametric models
## knn
```{r}
model_specs$knn = fgm ~ shot_dist + closest_defender_dist + touch_time + shot_clock
grids$knn <- expand.grid(k = seq(1, 352, length = 10))

# knn
tic()
fitted_models[["knn"]] <- train(model_specs$knn,
                                data = df_train,
                                method = "knn",
                                metric = optimisation_metric,
                                preProc = pre_proc_options,
                                trControl = fit_control,
                                tuneGrid = grids[["knn"]])
                                #tuneLength = length_tune_grid)
model_predictions[["knn"]] <- predict.train(fitted_models[["knn"]], df_test)
toc()
```

```{r}
confusionMatrix(model_predictions[["knn"]],df_test$fgm, positive = "hit")
#varImp(fitted_models$knn) not implicable to knn
plot(fitted_models[["knn"]])
fitted_models[["knn"]]
predictors(fitted_models[["knn"]])
# problem seems to be some shots that are predicted to surely miss but score instead
make_calibration_plot(df_train, fitted_models$knn)
make_calibration_plot(df_test, fitted_models$knn)

make_roc_plot(df_train, fitted_models$knn)
make_roc_plot(df_test, fitted_models$knn)

```


## SVM

```{r}
model_specs$svm = fgm ~ shot_dist + closest_defender_dist + touch_time + shot_clock
# create reduced df to analytically estimate sigma
reduced_set <- c("shot_dist", "closest_defender_dist", "touch_time", "shot_clock")
sigmaRangeReduced <- sigest(as.matrix(df_train[,reduced_set]))
grids$svm <- expand.grid(.sigma = sigmaRangeReduced[1], .C = 2^(seq(-1, -1)))
```
```{r}
fit_control_svm <- trainControl(method = "repeatedcv", number = 5, repeats = 1,
                            classProbs = TRUE,
                            summaryFunction = twoClassSummary)

# knn
tic()
fitted_models[["svm"]] <- train(df_train[,reduced_set], df_train$fgm,
                                method = "svmRadial",
                                metric = optimisation_metric,
                                preProc = pre_proc_options,
                                trControl = fit_control,
                                fit = FALSE,
                                tuneGrid = grids[["svm"]])
                                #tuneLength = length_tune_grid)
model_predictions[["svm"]] <- predict.train(fitted_models[["svm"]], df_test)
toc()
```

```{r}
confusionMatrix(model_predictions[["svm"]],df_test$fgm, positive = "hit")
#varImp(fitted_models$svm) not implicable to svm
plot(fitted_models[["svm"]])
fitted_models[["svm"]]
predictors(fitted_models[["svm"]])
# problem seems to be some shots that are predicted to surely miss but score instead
make_calibration_plot(df_train, fitted_models$svm)
make_calibration_plot(df_test, fitted_models$svm)

make_roc_plot(df_train, fitted_models$svm)
make_roc_plot(df_test, fitted_models$svm)

```


Next steps

0. SVM
1. Random forrests
2. Partial least squares
3. Neural Networks
